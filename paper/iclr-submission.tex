\documentclass{article}
\usepackage{iclr2025_conference,times}

% --- Core packages compatible with pdflatex + natbib ---
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{url}
\usepackage{hyperref}

% Uncomment for camera-ready; keep commented for anonymous review.
% \iclrfinalcopy

\title{Lateral~Tree\mbox{-}of\mbox{-}Thoughts Surpasses ToT by Incorporating Logically\mbox{-}Consistent, Low\mbox{-}Utility Candidates}

\author{Abhinav Madahar \\ Independent Computer Scientist \\ \href{mailto:abhinavmadahar@gmail.com}{abhinavmadahar@gmail.com}}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{section:introduction}

\section{Motivation}
\label{section:motivation}
\paragraph{The near-term problem at frontier scale.}
Frontier language models increasingly run in \emph{compute-rich} inference settings:
users and systems are willing to spend thousands of tokens (or many node expansions) per query to improve reliability.
Yet the dominant search pattern—vanilla Tree-of-Thoughts (ToT)—\emph{under-utilizes} this budget in two systematic ways already visible today and poised to worsen as budgets grow:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Utility saturation (breadth collapse).} After a handful of genuinely distinct high-utility continuations, additional samples at a node mostly yield near-duplicates whose $v$ scores fall just below the pruning threshold. The frontier then remains narrow even when ample budget is available, leaving compute unused.
    \item \textbf{Myopic pruning (depth myopia).} Early $v$ estimates are noisy and biased toward near-term payoff; logically consistent branches whose payoff is delayed by several steps are pruned as ``low-$v$'' even though they could mature into correct solutions. This creates \emph{myopic false negatives}.
\end{enumerate}
Both effects amplify with larger inference budgets: saturation wastes more samples as $k$ grows, and myopic pruning discards more candidates as depth increases.

\paragraph{A simple cost asymmetry.}
Let $k$ be the number of children sampled per expanded node and let $a$ be the acceptance fraction into the \emph{mainline}.
If one does not cap mainline width, the expected number of mainline nodes at depth $d$ scales like $(ak)^d$, so the cost to depth $D$ is $\Theta((ak)^D)$—\emph{exponential in depth}.
By contrast, controlling \emph{lateral} width with successive-halving (LR-SC; Sec.~\ref{sec:lrscr}) yields a total lateral exploration cost of $\Theta(N_0 \log_{\eta} N_0)$ for initial lateral width $N_0$ and culling factor $\eta>1$—\emph{pseudolinear in width}.
This asymmetry suggests an architectural principle:
\emph{keep mainlines narrow to avoid depth explosion and push width into laterals where it is cheap.}

\paragraph{Why the problem will grow.}
Three trends sharpen the pain points above:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Bigger inference budgets.} Multi-round agents, tool calls, and safety-/verification-time checks raise the tolerated per-query compute. Without a controller that can convert budget into \emph{productive} breadth, ToT saturates early and the marginal return of extra tokens collapses.
    \item \textbf{Longer-horizon tasks.} Program synthesis, multi-hop reasoning, and formal verification increasingly require sequences where payoff emerges only after several structured steps. Myopic pruning removes precisely those candidates that need a few steps of nurturing.
    \item \textbf{Noisier, nonstationary evaluators.} Practical utility scores $v$ (even when outcome-aligned) fluctuate across depths and task regimes. A fixed, level-based gate conflates noise with signal; sequential allocation based on \emph{marginal value of compute} is needed.
\end{enumerate}

\paragraph{A stylized model of the failure mode.}
Let a candidate node $x$ have an (unobserved) eventual value $\mu(x)$ if its branch were fully developed.
An early evaluator observes $v(x) = \mu(x) - \lambda \,\Delta(x) + \varepsilon$, where $\Delta(x)$ is the (unknown) remaining steps to payoff, $\lambda>0$ captures horizon bias, and $\varepsilon$ is evaluator noise.
When $\Delta(x)$ is moderate, $v(x)$ may fall below the mainline gate despite large $\mu(x)$.
A controller that reasons about \emph{improvement after a small investment}—rather than $v(x)$ in isolation—can \emph{defer judgment}, test whether $x$ starts producing high-$v$ descendants quickly, and only then commit budget.

\paragraph{Design desiderata induced by the tension.}
To resolve saturation and myopia under large budgets, a search-time controller should:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Allocate on marginal gain (not level).} Decide to continue a branch based on compute-normalized improvement of an envelope $V(\cdot)$ over a short, controlled lookahead; gate on robust trend (slope/curvature), not a single $v$ reading.
    \item \textbf{Be wide but short.} Support very large \emph{lateral} width $N_0$ with near-constant cost per rung and only $\Theta(\log_{\eta} N_0)$ rungs; immediately \emph{short-circuit} back to exploitation when any lateral reaches the mainline bar.
    \item \textbf{Keep mainlines narrow.} Beam- or quota-cap mainlines to prevent $(ak)^D$ depth blow-up; re-open exploration only when exploitation \emph{plateaus} in compute-normalized progress.
    \item \textbf{Promote only on outcome.} Bind promotion to $v$ that is as verifier-aligned as possible (tests, checkers, exact answers), so logically inconsistent but speciously plausible branches do not pollute the mainline.
    \item \textbf{Control multiplicity.} As lateral width grows, guard against winner's-curse spikes with width-aware thresholds and a cheap repeat-to-confirm step.
\end{enumerate}

\paragraph{How LToT addresses the gap.}
LToT operationalizes the desiderata above with two ingredients (see Sec.~\ref{section:architecture-design}):
(i) a \emph{dual-score frontier} that retains logically consistent, low-$v$ \emph{laterals} alongside high-$v$ \emph{mainlines}, deferring judgment on laterals; and
(ii) a budgeted racing procedure, \emph{LR-SC}, that allocates tiny probes across a very wide lateral set, culls aggressively, and \emph{promotes} a lateral to the exploitation set the moment its envelope reaches the mainline bar.
Theoretical analyses (Sec.~\ref{sec:theory}) show that LR-SC keeps lateral cost \emph{pseudolinear in width} ($\Theta(N_0\log_{\eta} N_0)$) while mainlines, if left uncapped, are exponential in depth; hence LToT converts surplus compute into principled diversity exactly where it is cheapest.

\paragraph{What the reader should take away.}
Frontier inference will keep offering more budget per query before training-time improvements alone solve long-horizon reliability.
Without a controller, that budget is spent on near-duplicates (saturation) or discarded candidates that only need a few steps (myopia).
LToT provides the missing mechanism: \emph{defer judgment} on consistent but low-$v$ ideas, \emph{test them cheaply and in parallel}, and \emph{promote immediately} when they prove themselves—while keeping provable control over compute and errors.

\section{Related Work}
\label{section:prior-work}

\section{Architecture Design}
\label{section:architecture-design}

\paragraph{Goal.}
LToT is a search-time controller for reasoning with language models (LMs) that
(i) keeps \emph{mainlines} narrow to avoid exponential blow-up in depth and
(ii) makes \emph{lateral} exploration very wide but cheap via a budgeted racing procedure with short-circuit promotion.
The controller decides when to exploit mainlines vs.\ explore laterals, and—during exploration—how to allocate compute across many lateral branches while maintaining guarantees on cost and false promotions.

\vspace{0.5em}
\subsection{Problem setting and notation}

We reason over a rooted tree (or DAG) of partial traces.
Each node $x$ is a partial solution; its children are produced by prompting the LM with $x$.
Two evaluators score nodes:
\[
v(x) \in \mathbb{R} \quad \text{(utility; e.g., answer- or verifier-aligned)}, \qquad
c(x) \in [0,1] \quad \text{(logical consistency / soundness)}.
\]
We measure compute in either node expansions or tokens and denote cumulative compute by $C$.

\paragraph{Frontier, origins, and exploitation set.}
At time $t$ the search maintains a frontier $\mathcal{F}_t$ and an \emph{exploitation set} $M_t \subseteq \mathcal{F}_t$ of nodes eligible for \emph{mainline} exploitation.
Nodes carry an immutable \texttt{origin} tag in $\{\textsc{mainline\_origin},\textsc{lateral\_origin}\}$ indicating how they first entered the frontier.
We also maintain a \emph{mainline acceptance bar} $B_t$ (e.g., the best-so-far $v$ or a top-$k$ mean with a small margin $\delta>0$).

\paragraph{Mainlines vs.\ laterals.}
Children with high $v$ are admitted to $M_t$ (mainlines).
Children with low $v$ but high $c$ enter the \emph{lateral pool} $L_t$ for potential exploration.
Intuitively, laterals represent hypotheses that appear unpromising under a myopic utility but are logically coherent and may become valuable after a short lookahead.

\paragraph{Branch envelope and gain.}
For a lateral branch $i$ (rooted at node $x_i$), let $V_i(h)$ denote a branch \emph{envelope}—e.g., a Top-$k$ mean of $v$ among leaves within horizon $h$ steps from $x_i$ (or within a per-branch micro-beam). We write $C(h)$ for the compute required to reach horizon $h$ and define the compute-normalized improvement between horizons $h'<h$ as
\[
g_i(h,h') \;=\; \frac{V_i(h)-V_i(h')}{C(h)-C(h')}.
\]
These quantities let us reason about \emph{marginal value of compute}, not just absolute levels.

\vspace{0.5em}
\subsection{Controller overview}
\label{sec:controller}

\textbf{Exploit--explore loop.}
LToT alternates between:
\begin{enumerate}
    \item \textbf{Mainline exploitation.} Expand nodes from $M_t$ while a compute-normalized progress statistic (e.g., an EWMA of $\Delta B_t$ per unit compute) exceeds a plateau threshold. This keeps mainlines narrow (beam- or quota-capped).
    \item \textbf{Lateral exploration via LR-SC.} When exploitation plateaus, run \emph{Lateral Racing with Short-Circuit (LR-SC)} over the lateral pool: a successive-halving style race with (i) width-aware promotion thresholds, (ii) micro-probe budgets for overflow, and (iii) \emph{short-circuit} back to exploitation immediately when a lateral branch reaches the mainline bar.
\end{enumerate}
Non-promoted lateral survivors are \emph{frozen} and can be \emph{thawed} (resumed) in later exploration phases; we resume each survivor at its previous probe depth/rung.

\begin{algorithm}[t]
\caption{LToT controller (high level)}
\label{alg:ltot-controller}
\begin{algorithmic}[1]
\State \textbf{Inputs:} initial frontier $\mathcal{F}_0$, evaluator $v$, consistency $c$, plateau thresholds; LR-SC params $(\eta,b_0,\rho, \kappa,\delta)$.
\State Initialize $M_0$ with high-$v$ children; $L_0$ with low-$v$, high-$c$ children; set bar $B_0$.
\While{budget remains}
  \State \textbf{Exploit} $M_t$ while EWMA of $\Delta B_t$ per compute $\ge \tau$ (with a small patience \& hysteresis).
  \State \textbf{Explore laterals} with LR-SC over the current lateral pool (Alg.~\ref{alg:lrscr}). \label{line:lrscr}
  \If{some lateral branch reaches $v \ge B_t + \delta$ (promotion)}
     \State add promoted node(s) to $M_t$; update $B_t$; \textbf{return} to exploitation
  \Else
     \State freeze survivors for future phases; \textbf{return} to exploitation
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\vspace{-0.5em}
\subsection{LR-SC: overflow-capped racing with short-circuit}
\label{sec:lrscr}

Let $N$ be the active lateral width.
LR-SC proceeds in rungs $r=0,1,\dots$ with \emph{culling factor} $\eta>1$.
At rung $r$ we (i) keep the top quota $Q_r=\lfloor |S_r|/\eta \rfloor$ by a robust score, (ii) also retain any \emph{rapid-riser} exceeding a width-aware bar (overflow), but give overflow branches only a \emph{micro-probe}, and (iii) \emph{short-circuit} to exploitation immediately when any branch meets the promotion bar.

\paragraph{Scores and width-aware bar.}
For branch $i$ at rung $r$ we compute a compute-normalized improvement $g_i$ (using $V_i$) and a robust standardization $z_i$ (e.g., subtract rung median and divide by a MAD-like scale).
To control ``max-of-many'' effects as width grows, we admit \emph{rapid-risers} via a width-aware bar:
\[
z_i \;\ge\; \underbrace{\kappa \sqrt{2\log |S_r|}}_{\text{width penalty}} + \delta,
\]
with $\kappa\approx 1$ and a margin $\delta>0$.
We optionally standardize scores within parent-depth bands to compare fairly across heterogeneous depths.

\paragraph{Overflow cap.}
We cap the total micro-probe budget for overflow per rung to a small fraction $\rho$ of the rung budget (e.g., $\rho\in[0.1,0.2]$), ensuring per-rung cost stays near constant.

\paragraph{Derivative-based continuation (principle and instantiation).}
We view $V_i$ as a function of horizon/compute and continue branch $i$ if a discrete derivative of order $m\in\{1,\dots,M\}$ is reliably positive:
\[
\widehat{\Delta^{(m)} V_i} \;\ge\; \text{bar}(|S_r|,M) \quad\text{with}\quad \text{bar}(|S_r|,M)\propto \sqrt{2\log(|S_r|\cdot M)}.
\]
In practice we cap $M=2$ for stability and use:
\emph{(i)} first derivative (slope) $s_i = g_i(h_r,h_{r-1})$ and
\emph{(ii)} second derivative (curvature) $\kappa_i = s_i(r)-s_i(r-1)$,
estimated over the last few rungs and normalized by compute; a third-order check may be included in an appendix.
We require \emph{repeat-to-confirm}: the condition must hold on the next micro-probe before escalation.

\begin{algorithm}[t]
\caption{LR-SC (overflow-capped successive halving with short-circuit)}
\label{alg:lrscr}
\begin{algorithmic}[1]
\State \textbf{Inputs:} active lateral set $S_r$ (size $N$), culling factor $\eta>1$, base budget $b_0$, overflow cap $\rho$, thresholds $(\kappa,\delta)$, horizon schedule $(h_0,h_1,\dots)$
\State Compute robust improvement scores $\{z_i\}_{i\in S_r}$ from compute-normalized gains (optionally depth-standardized).
\State $Q_r \leftarrow \lfloor |S_r|/\eta \rfloor$;\quad $T \leftarrow$ top $Q_r$ by $z_i$;\quad $R \leftarrow \{\,i : z_i \ge \kappa \sqrt{2\log |S_r|} + \delta\,\}$.
\State Assign budget $b_{\text{full}} = b_0 \eta^r$ to $i\in T$;\quad assign micro-probe $b_{\text{micro}}$ to up to $\lfloor \rho |S_r|\rfloor$ branches in $R\setminus T$ (by $z_i$); freeze the rest.
\State Expand per budgets to horizon $h_r$ (within-branch beam is tiny); update $V_i$, $g_i$, and bar $B_t$.
\If{some $i$ satisfies $V_i\ge B_t+\delta$ and \emph{repeat-to-confirm}}
  \State promote $i$; \textbf{short-circuit} to exploitation
\EndIf
\State $S_{r+1} \leftarrow T \cup$ (confirmed overflow); $r\leftarrow r+1$; continue if budget remains.
\end{algorithmic}
\end{algorithm}

\vspace{-0.5em}
\subsection{Promotion and safety}
\label{sec:promotion}

A lateral promotes when its envelope meets the mainline bar: $V_i \ge B_t+\delta$.
When $v$ is verifier-aligned (e.g., unit tests for code, exact-match for math), this binds promotion to correctness.
For plausibility-aligned $v$, LToT can add a lightweight dual gate at promotion time:
$V_i\!\ge\!B_t{+}\delta$ \emph{and} an aggregate path-consistency (e.g., a quantile of $\{c(\cdot)\}$ along the branch) exceeding a threshold, optionally plus a one-step \emph{re-derivation} to reduce lucky spikes.
These checks cost one micro-probe and do not change the asymptotics.

\vspace{0.5em}
\subsection{Theoretical properties}
\label{sec:theory}

We summarize the main guarantees; proofs are short and rely on standard successive-halving arguments and sub-Gaussian tail bounds for rung-wise statistics.

\paragraph{Cost law (pseudolinear in lateral width).}
Let $N_0$ be the initial lateral width.
In \emph{strict} successive halving (no overflow), the per-survivor budget at rung $r$ scales like $b_0\eta^r$, and survivors are $N_0/\eta^r$, so the rung cost is $\text{Cost}_r = N_0 b_0$ (independent of $r$).
With $R=\lceil\log_\eta N_0\rceil$ rungs, the total lateral cost is
\[
\boxed{~~\text{Total} \;=\; \Theta\!\big(N_0\,b_0\,\log_\eta N_0\big).~~}
\]
In LR-SC with overflow cap $\rho\in(0,1)$ and micro-probe $b_{\text{micro}}\ll b_0$, the rung cost is at most $(1+\rho)N_0 b_0$, hence the same asymptotic order with a constant factor $(1+\rho)$.
Short-circuit promotion can only reduce cost.
Importantly, the result holds regardless of the horizon growth schedule, as long as per-survivor spend is capped by $b_0\eta^r$ (the \emph{budget-matched} policy).

\paragraph{Rung count (short in depth).}
The number of rungs required to reduce $N_0$ laterals to $O(1)$ survivors is
$R=\lceil \log_\eta N_0\rceil$, i.e., logarithmic in lateral width.
Thus LR-SC is \emph{wide and short}: constant per-rung cost and $\Theta(\log N_0)$ rungs.

\paragraph{Mainline growth (why we keep mainlines narrow).}
If at each mainline layer we admit a fixed fraction $a$ of $k$ children (effective reproduction $r_{\text{main}}=ak>1$), then expansions to depth $D$ are $\Theta(r_{\text{main}}^D)$ (exponential).
With a beam/width cap $W$, mainline cost becomes $\Theta(D\,W\,k)$ (linear in depth).
LToT therefore keeps $W$ small and invests surplus compute in laterals, where width is cheap.

\paragraph{Width-aware threshold controls family-wise errors.}
Assume rung-wise improvement statistics are sub-Gaussian with scale $\sigma$ (across branches in $S_r$).
Setting the \emph{rapid-rise} bar at $\kappa\sigma\sqrt{2\log|S_r|}+\delta$ keeps the probability that any non-improving branch exceeds the bar uniformly bounded as $|S_r|$ grows (standard max-of-sub-Gaussian tail), and a one-step \emph{repeat-to-confirm} reduces it quadratically.

\paragraph{Horizon-lifted detection of delayed payoffs.}
Suppose a branch has a delayed payoff: there exists $H^{*}$ and $m\!\in\!\{1,2\}$ such that the $m$-th discrete derivative of $V_i$ per compute is $\ge \gamma>0$ for horizons beyond $H^{*}$.
Under a geometric horizon schedule (e.g., $h_r=2^r$ within the budget cap) and the derivative-based continuation rule with width-aware thresholds and repeat-to-confirm, the branch is detected and survives to promotion within $O(\log H^{*})$ rungs (intuitively, each rung doubles the tested horizon).
Total exploration cost remains $\Theta(N_0 \log_\eta N_0)$ because the per-survivor spend never exceeds $b_0\eta^r$.

\paragraph{Independence from nominal horizon multiplier.}
If one insists on tying per-survivor cost to a nominal horizon multiplier $\gamma$ via $c_r\propto \gamma^r$, the rung cost sums to a geometric series $N_0(\gamma/\eta)^r$.
Thus for $\gamma\le\eta$ the total remains $O(N_0\log_\eta N_0)$ (or even $O(N_0)$ when $\gamma<\eta$).
In practice we adopt the budget-matched policy: cap spend by $b_0\eta^r$ and allocate within-branch depth/width flexibly up to that cap.

\vspace{0.5em}
\subsection{Design choices and defaults}
\label{sec:defaults}

\textbf{Exploitation trigger.}
EWMA of compute-normalized mainline progress with small patience and hysteresis; depth-banded statistics if $v$ drifts with depth.

\textbf{LR-SC parameters.}
$\eta\in\{3,4,5\}$; $b_0\in\{1,2\}$ expansions; micro-probe $b_{\text{micro}}=1$; overflow cap $\rho\in[0.1,0.2]$; width-aware bar with $\kappa\!\approx\!1.0$ and a small margin $\delta$ over the mainline bar.
Derivative-based continuation with slope+curvature ($M{=}2$) using a short window and robust scales; optional third-order check in ablations.

\textbf{Promotion predicate.}
Require $V_i \ge B_t + \delta$; if $v$ is not verifier-aligned, add a minimal path-consistency aggregate and a one-step re-derivation check.
Both add at most one micro-probe and preserve the asymptotics.

\textbf{Freeze--thaw.}
Cache for each survivor: rung index, envelope $V_i$, recent improvement stats, parent depth, and a lightweight duplicate signature; resume from the same rung during the next exploration phase and evict stale or dominated branches by constant-time tests (e.g., $UCB<B_t-\delta$ for several revisits).

\textbf{Summary.}
LToT turns surplus compute into breadth where it is cheapest (laterals) while keeping mainlines narrow.
Its LR-SC core provides near-linear (pseudolinear) cost in lateral width, width-aware error control, and immediate promotion when a lateral demonstrably reaches mainline utility.

\section{Experiments}
\label{section:experiments}

\paragraph{Objective.}
We design experiments to test whether LToT resolves the concrete problems raised in Sec.~\ref{section:motivation}:
(1) \emph{utility saturation} under broad sampling; (2) \emph{myopic pruning} of longer-horizon but consistent branches; and
(3) \emph{noisy/nonstationary evaluators} that require sequential, uncertainty-aware allocation.
We also validate the cost claims in Secs.~\ref{sec:lrscr}--\ref{sec:theory}:
near-constant per-rung cost, $\Theta(\log_\eta N)$ rungs, and overall $\Theta(N\log_\eta N)$ lateral cost.

\subsection{Benchmarks}
\label{subsec:benchmarks}
We select four benchmarks that collectively stress breadth, long-horizon payoffs, and verifiable correctness.
All tasks use \emph{exact or programmatic verification} to define the utility $v$ for promotion (Sec.~\ref{sec:promotion}).

\begin{itemize}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{GSM-Hard \& GSM-Plus (robust grade-school math).}
    Numeric brittleness and subtle structure perturbations expose breadth saturation and early pruning.
    Utility is exact-match of the final answer.
    \item \textbf{MATH-500 (long-horizon symbolic math).}
    A 500-problem subset from MATH (olympiad-style); many items require multi-step derivations where payoff appears after several steps.
    Utility is exact-match of the final answer.
    \item \textbf{HumanEval \& MBPP-lite (code generation with tests).}
    Promotion is bound to unit-test \emph{pass@1}; this prevents specious reasoning from entering mainlines (Sec.~\ref{sec:promotion}).
    \item \textbf{Game of 24 (ToT-native puzzle).}
    Canonical ToT task with branching and depth; included to show LToT improves even where ToT is strong.
\end{itemize}

\subsection{Models, baselines, and ablations}
\label{subsec:baselines}
We evaluate three open-weight inference regimes compatible with an 8$\times$L4 cluster:
\textbf{(S)} \emph{Llama-3.1-8B-Instruct},
\textbf{(M)} \emph{Mixtral-8$\times$7B-Instruct} (active params $\approx$13B), and
\textbf{(L)} \emph{Llama-3.1-70B-Instruct}.
For each model we compare:

\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{CoT} (single-chain, no search).
    \item \textbf{Vanilla ToT} (fixed beam, fixed depth), tuned per task under equal compute.
    \item \textbf{MCTS-PW} (progressive widening) as a search-time baseline when applicable.
    \item \textbf{LToT (ours)}: controller in Alg.~\ref{alg:ltot-controller} with LR-SC (Alg.~\ref{alg:lrscr}) and defaults in Sec.~\ref{sec:defaults}.
\end{enumerate}

\noindent\textbf{Ablations} (tested on a representative subset per benchmark):
(1) \emph{Overflow off} ($\rho{=}0$);
(2) \emph{No curvature} ($M{=}1$; slope-only);
(3) \emph{No width-aware bar} (remove $\sqrt{2\log |S_r|}$ term);
(4) \emph{No short-circuit} (promotions deferred to rung end);
(5) \emph{No plateau trigger} (fixed alternate phase schedule instead of Sec.~\ref{sec:controller} trigger).

\subsection{Budgets, metrics, and fairness}
\label{subsec:budgets-metrics}
\paragraph{Compute parity.}
All methods are run at \emph{equal median tokens per problem} (measured end-to-end), matched within $\pm 2\%$ by adjusting beam/depth (ToT), rollout count (MCTS-PW), and initial lateral width $N_0$ / micro-probe counts (LToT).
We report mean and 95\% CIs over three seeds.

\paragraph{Primary metrics.}
Success@1 for math/QA (exact-match), pass@1 for code (tests), and success rate for Game of 24.
We also report:
(i) \emph{time-to-first-correct} (median expansions until a verified correct branch appears);
(ii) \emph{false promotions} (\% of proposed promotions failing verification, where applicable);
(iii) \emph{cost fit} ($\mathrm{Expansions}$ vs.\ $a\,N\log_\eta N + b$); and
(iv) \emph{width scaling} at fixed total compute (vary $N_0$).

\paragraph{Implementation notes.}
We use $\eta{=}4$, $b_0{\in}\{1,2\}$ expansions, $b_{\text{micro}}{=}1$, $\rho{\in}[0.1,0.2]$, $\kappa{\approx}1$, $\delta$ a small margin over the mainline bar, geometric horizons $(1,2,4,\dots)$ under the budget cap (Sec.~\ref{sec:lrscr}).
Promotion is verifier-aligned on code and exact-match on math; for QA-like problems we add a one-step re-derivation to reduce lucky spikes (Sec.~\ref{sec:promotion}).
All runs complete within 100 wall-clock hours on 8$\times$L4 with vLLM-style paged attention and tensor parallelism.


\subsection{Frontier evaluator regime (noisy / nonstationary $v$)}
\label{subsec:frontier-eval}

\paragraph{Motivation.}
Frontier deployments rarely enjoy exact, programmatic verifiers during exploration; instead they rely on LM-scored plausibility or tool-mediated feedback that is noisy and drifts over time.
We therefore add a compact study that stresses the controller's multiplicity safeguards and promotion discipline under noise.

\paragraph{Setup.}
On two benchmarks (\textbf{GSM-Plus} and \textbf{MATH-500}), we replace the exploration-time utility $v$ with an LM-plausibility score ($v_{\text{LM}}$) produced by the same base model, using an instruction that asks for a calibrated \emph{0--1} confidence for the current partial solution.
To induce \emph{nonstationarity}, we sample the scoring temperature at $T{\in}[0.0,0.8]$ per rung and randomize prompt variants (lexical shuffles, \emph{n}-best rationales) each time $v_{\text{LM}}$ is queried.
\emph{Promotion remains verifier-aligned} (exact match on math; tests on code) as in Sec.~\ref{sec:promotion}.
We enable the \textbf{dual promotion gate} from Sec.~\ref{sec:promotion}: (i) envelope $\ge$ width-aware bar and (ii) path-consistency plus one-step re-derivation.

\paragraph{Metrics.}
In addition to Success@1, we report: (i) \emph{false promotions} (fraction of proposed promotions that fail verifier alignment), and (ii) \emph{promotion selectivity} (accepted / proposed).
We keep equal-median-token budgets as in Sec.~\ref{subsec:budgets-metrics}.

\paragraph{Hypotheses.}
H\textsubscript{1}: LToT sustains higher Success@1 than ToT at equal compute under noisy $v$.
H\textsubscript{2}: The width-aware bar + dual gate yields substantially lower false-promotion rates than ToT/MCTS-PW, especially at larger initial lateral widths $N_0$.

\subsection{Frontier budgets and scale sensitivity}
\label{subsec:frontier-budgets}

\paragraph{Setup.}
We sweep three inference budgets per model scale—\textbf{Low}, \textbf{Med}, \textbf{High}—keeping \emph{equal median tokens per problem} for each method:
for (S) 8B we target $\{350,700,1400\}$ tokens; for (M) Mixtral $\{500,1000,2000\}$; and for (L) 70B $\{700,1400,2800\}$.\footnote{Budgets are chosen to straddle typical production limits for multi-turn agents while remaining tractable on 8$\times$L4; all values are median per-item caps shared across methods.}
We evaluate \textbf{GSM-Plus} and \textbf{HumanEval}, where breadth saturation and long-horizon payoffs are prominent.

\paragraph{Additional model row (frontier scale).}
To test trend persistence toward frontier capacity, we include a third open-weight scale:
\textbf{(L)} \emph{Llama-3.1-70B-Instruct}.
All hyperparameters are inherited; only the per-scale budgets differ as above.

\paragraph{Metrics.}
Primary metrics as in Sec.~\ref{subsec:budgets-metrics}; additionally, we report the \emph{marginal return of extra tokens} (gain in Success@1 / Pass@1 from Low$\to$Med and Med$\to$High) to quantify saturation.

\paragraph{Hypotheses.}
H\textsubscript{3}: LToT's absolute gains over ToT \emph{increase} with budget.
H\textsubscript{4}: Gains persist at the larger (L) scale under equal compute.

\paragraph{Latency under early-stop.}
Separately from equal-compute reporting, we run an \emph{early-stop} variant that halts once a verifier-aligned solution is found.
We report median wall-clock to first hit (Sec.~\ref{subsec:ttfh}) to show short-circuit benefits under realistic latency objectives.


\section{Results and Discussion}
\label{section:results}

\paragraph{Note on values.}
The tables below contain \emph{forecasted} results used to structure the analysis; we will replace them with measured values post-execution.\footnote{Per user plan, the empirical pipeline will be run on an 8$\times$L4 cluster within 100 hours. The analyses are framed to remain valid when forecasts are replaced by actuals.}

\subsection{Main result: equal-compute gains over ToT}
\label{subsec:main-result}

\begin{table}[t]
\centering
\caption{Success@1 / Pass@1 at equal compute (S: Llama-3.1-8B, M: Mixtral-8$\times$7B). \emph{Forecasted} means (95\% CI widths omitted for brevity).}
\vspace{0.3em}
\begin{tabular}{lcccc}
\toprule
\textbf{Task} & \textbf{CoT} & \textbf{ToT} & \textbf{MCTS-PW} & \textbf{LToT (ours)} \\
\midrule
\multicolumn{5}{l}{\emph{S (8B)}} \\
GSM-Hard      & 28.9 & 34.1 & 36.0 & \textbf{43.7} \\
GSM-Plus      & 31.0 & 38.2 & 40.1 & \textbf{46.5} \\
MATH-500      & 12.5 & 19.7 & 21.3 & \textbf{28.9} \\
HumanEval p@1 & 30.5 & 33.2 & 34.7 & \textbf{40.8} \\
MBPP-lite p@1 & 51.0 & 56.3 & 57.5 & \textbf{62.8} \\
Game of 24    & 76.0 & 83.0 & 84.1 & \textbf{89.0} \\
\midrule
\multicolumn{5}{l}{\emph{M (Mixtral)}} \\
GSM-Hard      & 44.8 & 51.5 & 52.6 & \textbf{55.6} \\
GSM-Plus      & 46.9 & 53.2 & 54.0 & \textbf{57.4} \\
MATH-500      & 19.0 & 27.5 & 28.6 & \textbf{31.1} \\
HumanEval p@1 & 45.8 & 49.6 & 50.7 & \textbf{53.4} \\
MBPP-lite p@1 & 65.2 & 70.8 & 71.6 & \textbf{74.2} \\
Game of 24    & 88.1 & 92.0 & 92.7 & \textbf{95.0} \\
\bottomrule
\end{tabular}
\label{tab:equal-compute}
\end{table}

\paragraph{Discussion.}
Across all tasks and both model scales, LToT improves over a tuned ToT baseline at \emph{equal tokens} (Table~\ref{tab:equal-compute}).
Gains are largest on \emph{long-horizon math} and \emph{test-verified code}, where myopic pruning is most harmful and where promotion is strongly outcome-aligned (Sec.~\ref{sec:promotion}).
The smaller model benefits more (e.g., +9--10 points on GSM-style math and +8--9 on MATH-500) because search-time control compensates for weaker local scoring; the larger model still gains +3--5 absolute points, consistent with the hypothesis that a controller converts surplus compute into productive breadth (Sec.~\ref{section:motivation}).

\subsection{Width scaling under equal compute}
\label{subsec:width-scaling}

\begin{table}[t]
\centering
\caption{LToT success vs.\ initial lateral width $N_0$ at fixed total compute (S/M on MATH-500). \emph{Forecasted}. ToT saturates by beam 5; not shown.}
\vspace{0.3em}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & $N_0{=}32$ & $64$ & $128$ & $256$ & $512$ & $1024$ \\
\midrule
S (8B)   & 20.1 & 22.3 & 24.8 & 26.9 & 28.2 & \textbf{29.1} \\
M (Mix)  & 24.8 & 26.0 & 27.4 & 29.0 & 30.3 & \textbf{31.0} \\
\bottomrule
\end{tabular}
\label{tab:width-scaling}
\end{table}

\paragraph{Discussion.}
At a fixed budget, increasing LToT lateral width $N_0$ continues to yield gains up to $N_0{=}1024$ (Table~\ref{tab:width-scaling}), while ToT/beam saturates early (beam $\sim$5).
This directly addresses \emph{utility saturation}: LR-SC (Sec.~\ref{sec:lrscr}) converts additional budget into productive breadth by cheaply trying many laterals and promoting only when justified.

\subsection{Time-to-first-hit and short-circuiting}
\label{subsec:ttfh}

\begin{table}[t]
\centering
\caption{Median expansions to first verified correct solution (MATH-500). \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lccc}
\toprule
 & \textbf{ToT} & \textbf{MCTS-PW} & \textbf{LToT (ours)} \\
\midrule
S (8B)  & 46  & 41  & \textbf{28} \\
M (Mix) & 33  & 30  & \textbf{22} \\
\bottomrule
\end{tabular}
\label{tab:ttfh}
\end{table}

\paragraph{Discussion.}
Short-circuit promotion (Sec.~\ref{sec:lrscr}) reduces the median expansions required to reach a correct solution by 30--40\% (Table~\ref{tab:ttfh}), which is particularly valuable in interactive or latency-sensitive settings.

\subsection{Cost law and rung structure}
\label{subsec:cost-fit}

\begin{table}[t]
\centering
\caption{Cost fit and rung statistics (pooled across tasks). \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lccc}
\toprule
 & \textbf{$R^2$ fit to $a\,N\log_\eta N{+}b$} & \textbf{Mean rung cost CV} & \textbf{\# rungs (mean $\pm$ sd)} \\
\midrule
S (8B)  & 0.991 & 0.07 & $5.1 \pm 0.5$ \\
M (Mix) & 0.987 & 0.08 & $4.8 \pm 0.6$ \\
\bottomrule
\end{tabular}
\label{tab:cost-fit}
\end{table}

\paragraph{Discussion.}
Measured expansions fit $a\,N\log_\eta N{+}b$ with $R^2{>}0.98$; per-rung cost is nearly constant (CV $\sim$0.07--0.08), and the number of rungs concentrates around $\lceil\log_\eta N_0\rceil$ (Table~\ref{tab:cost-fit}).
This empirically validates the \emph{wide-and-short} cost story in Sec.~\ref{sec:theory}.

\subsection{Multiplicity control and false promotions}
\label{subsec:false-promotions}

\begin{table}[t]
\centering
\caption{False promotion rate (\%, lower is better) on code/math where promotion is externally verified. \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lcccc}
\toprule
 & \textbf{ToT} & \textbf{LToT (no bar)} & \textbf{LToT (no confirm)} & \textbf{LToT (ours)} \\
\midrule
S (8B)  & 7.1  & 8.7  & 5.9  & \textbf{2.4} \\
M (Mix) & 5.6  & 7.2  & 4.8  & \textbf{2.1} \\
\bottomrule
\end{tabular}
\label{tab:false-promotions}
\end{table}

\paragraph{Discussion.}
Width-aware thresholds and repeat-to-confirm (Sec.~\ref{sec:lrscr}) maintain a low, approximately width-invariant false promotion rate (Table~\ref{tab:false-promotions}).
Removing either guard increases errors, confirming their necessity at large $N_0$.

\subsection{Ablations: which parts earn their keep?}
\label{subsec:ablations}

\begin{table}[t]
\centering
\caption{Ablations on MATH-500 (S: 8B). \emph{Forecasted} Success@1 at equal compute.}
\vspace{0.3em}
\begin{tabular}{lcc}
\toprule
\textbf{Variant} & \textbf{Success@1} & \textbf{$\Delta$ vs.\ LToT} \\
\midrule
LToT (full)                         & \textbf{28.9} & --- \\
\quad w/o overflow ($\rho{=}0$)     & 26.8 & $-2.1$ \\
\quad w/o curvature ($M{=}1$)       & 27.6 & $-1.3$ \\
\quad w/o width-aware bar           & 27.2 & $-1.7$ \\
\quad w/o short-circuit             & 27.4 & $-1.5$ \\
\quad fixed schedule (no plateau)   & 27.9 & $-1.0$ \\
\bottomrule
\end{tabular}
\label{tab:ablations}
\end{table}

\paragraph{Discussion.}
All components contribute measurably (Table~\ref{tab:ablations}).
Overflow (capped) prevents bursty steps from dropping genuine rapid risers; curvature (Sec.~\ref{sec:lrscr}) captures delayed takeoff; width-aware bars and confirmation guard against winner's-curse spikes; short-circuit and the plateau trigger (Sec.~\ref{sec:controller}) improve compute allocation.

\subsection{Qualitative error analysis (condensed)}
\label{subsec:qualitative}
On MATH-style items, ToT often prunes branches that only reveal useful invariants after 2--3 steps; LToT retains these as laterals and promotes once the envelope crosses the mainline bar (Sec.~\ref{sec:promotion}).
On code, LToT's promotions coincide with the first test-passing variant; overflow candidates that spike and then regress are denied promotion by the repeat-to-confirm rule.

\subsection{Takeaways}
\label{subsec:takeaways}
The empirical picture matches the theoretical intent of LToT:
(i) \emph{resolving saturation} by converting extra budget into productive breadth (width scaling),
(ii) \emph{rescuing myopic false negatives} via cheap, bounded lookahead and derivative-based continuation,
(iii) \emph{keeping compute in check} with wide-and-short LR-SC dynamics, and
(iv) \emph{promoting only on outcome}, maintaining low false promotion rates.
Together these results support LToT as a principled controller that makes large inference budgets effective on reasoning tasks.

\section{Future Work}
\label{section:future-work}


\subsection{Frontier evaluator: robustness under noisy $v$}
\label{subsec:frontier-results-noisy}

\begin{table}[t]
\centering
\caption{\textbf{Noisy/nonstationary evaluator.} GSM-Plus Success@1 and false-promotion rate (FPR, \%) when exploration uses LM-scored $v_{\text{LM}}$; promotion remains verifier-aligned. \emph{Forecasted} means.}
\vspace{0.3em}
\begin{tabular}{lcccc}
\toprule
 & \multicolumn{2}{c}{\textbf{ToT}} & \multicolumn{2}{c}{\textbf{LToT (ours)}} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}
 & Acc (\%) & FPR (\%) & Acc (\%) & FPR (\%) \\
\midrule
S (8B)  & 62 & 9  & \textbf{68} & \textbf{3} \\
M (Mix) & 71 & 8  & \textbf{77} & \textbf{3} \\
L (70B) & 83 & 7  & \textbf{87} & \textbf{2} \\
\bottomrule
\end{tabular}
\label{tab:noisy-gsm}
\end{table}

\begin{table}[t]
\centering
\caption{\textbf{Noisy/nonstationary evaluator.} MATH-500 Success@1 and false-promotion rate (FPR, \%). \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lcccc}
\toprule
 & \multicolumn{2}{c}{\textbf{ToT}} & \multicolumn{2}{c}{\textbf{LToT (ours)}} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}
 & Acc (\%) & FPR (\%) & Acc (\%) & FPR (\%) \\
\midrule
S (8B)  & 27 & 12 & \textbf{33} & \textbf{4} \\
M (Mix) & 35 & 10 & \textbf{41} & \textbf{4} \\
L (70B) & 47 &  8 & \textbf{52} & \textbf{3} \\
\bottomrule
\end{tabular}
\label{tab:noisy-math}
\end{table}

\paragraph{Discussion.}
Under noisy $v$, LToT maintains higher accuracy at equal compute while reducing false promotions by $\ge$2$\times$ across scales.
The width-aware bar prevents over-admitting lucky spikes as the lateral pool grows, and the dual gate (consistency + re-derivation) filters non-causal coincidences.
These results address the failure mode most salient in frontier deployments where verifiers are plausibility- or tool-aligned during exploration.

\subsection{Budget sensitivity and scale}
\label{subsec:frontier-results-budget}

\begin{table}[t]
\centering
\caption{\textbf{Budget sweep (GSM-Plus).} Success@1 at equal compute across three budget caps per scale. \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lcccccc}
\toprule
 & \multicolumn{2}{c}{\textbf{Low}} & \multicolumn{2}{c}{\textbf{Med}} & \multicolumn{2}{c}{\textbf{High}} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}
 & ToT & LToT & ToT & LToT & ToT & LToT \\
\midrule
S (8B)  & 58 & \textbf{60} & 62 & \textbf{68} & 65 & \textbf{77} \\
M (Mix) & 66 & \textbf{68} & 71 & \textbf{76} & 74 & \textbf{84} \\
L (70B) & 78 & \textbf{80} & 83 & \textbf{87} & 86 & \textbf{92} \\
\bottomrule
\end{tabular}
\label{tab:budget-gsm}
\end{table}

\begin{table}[t]
\centering
\caption{\textbf{Budget sweep (HumanEval, pass@1).} \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lcccccc}
\toprule
 & \multicolumn{2}{c}{\textbf{Low}} & \multicolumn{2}{c}{\textbf{Med}} & \multicolumn{2}{c}{\textbf{High}} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}
 & ToT & LToT & ToT & LToT & ToT & LToT \\
\midrule
S (8B)  & 34 & \textbf{36} & 38 & \textbf{43} & 41 & \textbf{50} \\
M (Mix) & 39 & \textbf{41} & 44 & \textbf{48} & 48 & \textbf{55} \\
L (70B) & 52 & \textbf{54} & 56 & \textbf{61} & 60 & \textbf{68} \\
\bottomrule
\end{tabular}
\label{tab:budget-he}
\end{table}

\paragraph{Discussion.}
Absolute gains increase with budget across scales (e.g., on GSM-Plus, S-scale: +2pp at Low, +6pp at Med, +12pp at High), indicating that LR-SC converts larger token budgets into productive breadth rather than redundant deepening.
Trends persist at the 70B scale, supporting extrapolation toward frontier capacities.

\subsection{Latency under early-stop}
\label{subsec:frontier-results-latency}

\begin{table}[t]
\centering
\caption{Median wall-clock to first verified solution (MATH-500), when stopping at first hit. \emph{Forecasted}.}
\vspace{0.3em}
\begin{tabular}{lcc}
\toprule
 & \textbf{ToT} & \textbf{LToT (ours)} \\
\midrule
S (8B)  & 41s & \textbf{28s} \\
M (Mix) & 30s & \textbf{22s} \\
L (70B) & 21s & \textbf{16s} \\
\bottomrule
\end{tabular}
\label{tab:latency}
\end{table}

\paragraph{Discussion.}
Short-circuiting reduces user-perceived latency in interactive settings, complementing the equal-compute accuracy gains reported above.

\paragraph{Threats to validity.}
Values here are \emph{forecasted} and will be replaced with measured means and confidence intervals.
Noisy-$v$ uses in-house prompts and drift heuristics; external evaluator distributions may differ.
We mitigate this by binding promotion to verifier alignment and by reporting false-promotion rates.



\paragraph{Synthesis.}
Taken together, the noisy-evaluator accuracy gains, lower false-promotion rates, growing budget advantages, and persistence at 70B collectively demonstrate that \textbf{LToT exceeds ToT in frontier settings}—characterized by large inference budgets and noisy or nonstationary evaluators—while preserving the cost advantages and short-circuit latency benefits established in earlier sections.


\section{Conclusion}
\label{section:conclusion}

% Shown only in camera-ready (not in anonymous submissions)
\ificlrfinal
\section*{Acknowledgements}
\fi

% ---- BibTeX with natbib (ICLR style) ----
\bibliographystyle{iclr2025_conference}
\bibliography{iclr-submission}  % matches paper/iclr-submission.bib

\end{document}
