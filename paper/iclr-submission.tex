\documentclass{article}
\usepackage{iclr2025_conference,times}

% --- Core packages compatible with pdflatex + natbib ---
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{url}
\usepackage{hyperref}

% Uncomment for camera-ready; keep commented for anonymous review.
% \iclrfinalcopy

\title{Lateral~Tree\mbox{-}of\mbox{-}Thoughts Surpasses ToT by Incorporating Logically\mbox{-}Consistent, Low\mbox{-}Utility Candidates}

\author{Abhinav Madahar \\ Independent Computer Scientist \\ \href{mailto:abhinavmadahar@gmail.com}{abhinavmadahar@gmail.com}}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{section:introduction}

\section{Motivation}
\label{section:motivation}
\paragraph{The near-term problem at frontier scale.}
Frontier language models increasingly run in \emph{compute-rich} inference settings:
users and systems are willing to spend thousands of tokens (or many node expansions) per query to improve reliability.
Yet the dominant search pattern—vanilla Tree-of-Thoughts (ToT)—\emph{under-utilizes} this budget in two systematic ways already visible today and poised to worsen as budgets grow:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Utility saturation (breadth collapse).} After a handful of genuinely distinct high-utility continuations, additional samples at a node mostly yield near-duplicates whose $v$ scores fall just below the pruning threshold. The frontier then remains narrow even when ample budget is available, leaving compute unused.
    \item \textbf{Myopic pruning (depth myopia).} Early $v$ estimates are noisy and biased toward near-term payoff; logically consistent branches whose payoff is delayed by several steps are pruned as ``low-$v$'' even though they could mature into correct solutions. This creates \emph{myopic false negatives}.
\end{enumerate}
Both effects amplify with larger inference budgets: saturation wastes more samples as $k$ grows, and myopic pruning discards more candidates as depth increases.

\paragraph{A simple cost asymmetry.}
Let $k$ be the number of children sampled per expanded node and let $a$ be the acceptance fraction into the \emph{mainline}.
If one does not cap mainline width, the expected number of mainline nodes at depth $d$ scales like $(ak)^d$, so the cost to depth $D$ is $\Theta((ak)^D)$—\emph{exponential in depth}.
By contrast, controlling \emph{lateral} width with successive-halving (LR-SC; Sec.~\ref{sec:lrscr}) yields a total lateral exploration cost of $\Theta(N_0 \log_{\eta} N_0)$ for initial lateral width $N_0$ and culling factor $\eta>1$—\emph{pseudolinear in width}.
This asymmetry suggests an architectural principle:
\emph{keep mainlines narrow to avoid depth explosion and push width into laterals where it is cheap.}

\paragraph{Why the problem will grow.}
Three trends sharpen the pain points above:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Bigger inference budgets.} Multi-round agents, tool calls, and safety-/verification-time checks raise the tolerated per-query compute. Without a controller that can convert budget into \emph{productive} breadth, ToT saturates early and the marginal return of extra tokens collapses.
    \item \textbf{Longer-horizon tasks.} Program synthesis, multi-hop reasoning, and formal verification increasingly require sequences where payoff emerges only after several structured steps. Myopic pruning removes precisely those candidates that need a few steps of nurturing.
    \item \textbf{Noisier, nonstationary evaluators.} Practical utility scores $v$ (even when outcome-aligned) fluctuate across depths and task regimes. A fixed, level-based gate conflates noise with signal; sequential allocation based on \emph{marginal value of compute} is needed.
\end{enumerate}

\paragraph{A stylized model of the failure mode.}
Let a candidate node $x$ have an (unobserved) eventual value $\mu(x)$ if its branch were fully developed.
An early evaluator observes $v(x) = \mu(x) - \lambda \,\Delta(x) + \varepsilon$, where $\Delta(x)$ is the (unknown) remaining steps to payoff, $\lambda>0$ captures horizon bias, and $\varepsilon$ is evaluator noise.
When $\Delta(x)$ is moderate, $v(x)$ may fall below the mainline gate despite large $\mu(x)$.
A controller that reasons about \emph{improvement after a small investment}—rather than $v(x)$ in isolation—can \emph{defer judgment}, test whether $x$ starts producing high-$v$ descendants quickly, and only then commit budget.

\paragraph{Design desiderata induced by the tension.}
To resolve saturation and myopia under large budgets, a search-time controller should:
\begin{enumerate}[leftmargin=*, itemsep=2pt, topsep=2pt]
    \item \textbf{Allocate on marginal gain (not level).} Decide to continue a branch based on compute-normalized improvement of an envelope $V(\cdot)$ over a short, controlled lookahead; gate on robust trend (slope/curvature), not a single $v$ reading.
    \item \textbf{Be wide but short.} Support very large \emph{lateral} width $N_0$ with near-constant cost per rung and only $\Theta(\log_{\eta} N_0)$ rungs; immediately \emph{short-circuit} back to exploitation when any lateral reaches the mainline bar.
    \item \textbf{Keep mainlines narrow.} Beam- or quota-cap mainlines to prevent $(ak)^D$ depth blow-up; re-open exploration only when exploitation \emph{plateaus} in compute-normalized progress.
    \item \textbf{Promote only on outcome.} Bind promotion to $v$ that is as verifier-aligned as possible (tests, checkers, exact answers), so logically inconsistent but speciously plausible branches do not pollute the mainline.
    \item \textbf{Control multiplicity.} As lateral width grows, guard against winner's-curse spikes with width-aware thresholds and a cheap repeat-to-confirm step.
\end{enumerate}

\paragraph{How LToT addresses the gap.}
LToT operationalizes the desiderata above with two ingredients (see Sec.~\ref{section:architecture-design}):
(i) a \emph{dual-score frontier} that retains logically consistent, low-$v$ \emph{laterals} alongside high-$v$ \emph{mainlines}, deferring judgment on laterals; and
(ii) a budgeted racing procedure, \emph{LR-SC}, that allocates tiny probes across a very wide lateral set, culls aggressively, and \emph{promotes} a lateral to the exploitation set the moment its envelope reaches the mainline bar.
Theoretical analyses (Sec.~\ref{sec:theory}) show that LR-SC keeps lateral cost \emph{pseudolinear in width} ($\Theta(N_0\log_{\eta} N_0)$) while mainlines, if left uncapped, are exponential in depth; hence LToT converts surplus compute into principled diversity exactly where it is cheapest.

\paragraph{What the reader should take away.}
Frontier inference will keep offering more budget per query before training-time improvements alone solve long-horizon reliability.
Without a controller, that budget is spent on near-duplicates (saturation) or discarded candidates that only need a few steps (myopia).
LToT provides the missing mechanism: \emph{defer judgment} on consistent but low-$v$ ideas, \emph{test them cheaply and in parallel}, and \emph{promote immediately} when they prove themselves—while keeping provable control over compute and errors.

\section{Related Work}
\label{section:prior-work}

\section{Architecture Design}
\label{section:architecture-design}

\paragraph{Goal.}
LToT is a search-time controller for reasoning with language models (LMs) that
(i) keeps \emph{mainlines} narrow to avoid exponential blow-up in depth and
(ii) makes \emph{lateral} exploration very wide but cheap via a budgeted racing procedure with short-circuit promotion.
The controller decides when to exploit mainlines vs.\ explore laterals, and—during exploration—how to allocate compute across many lateral branches while maintaining guarantees on cost and false promotions.

\vspace{0.5em}
\subsection{Problem setting and notation}

We reason over a rooted tree (or DAG) of partial traces.
Each node $x$ is a partial solution; its children are produced by prompting the LM with $x$.
Two evaluators score nodes:
\[
v(x) \in \mathbb{R} \quad \text{(utility; e.g., answer- or verifier-aligned)}, \qquad
c(x) \in [0,1] \quad \text{(logical consistency / soundness)}.
\]
We measure compute in either node expansions or tokens and denote cumulative compute by $C$.

\paragraph{Frontier, origins, and exploitation set.}
At time $t$ the search maintains a frontier $\mathcal{F}_t$ and an \emph{exploitation set} $M_t \subseteq \mathcal{F}_t$ of nodes eligible for \emph{mainline} exploitation.
Nodes carry an immutable \texttt{origin} tag in $\{\textsc{mainline\_origin},\textsc{lateral\_origin}\}$ indicating how they first entered the frontier.
We also maintain a \emph{mainline acceptance bar} $B_t$ (e.g., the best-so-far $v$ or a top-$k$ mean with a small margin $\delta>0$).

\paragraph{Mainlines vs.\ laterals.}
Children with high $v$ are admitted to $M_t$ (mainlines).
Children with low $v$ but high $c$ enter the \emph{lateral pool} $L_t$ for potential exploration.
Intuitively, laterals represent hypotheses that appear unpromising under a myopic utility but are logically coherent and may become valuable after a short lookahead.

\paragraph{Branch envelope and gain.}
For a lateral branch $i$ (rooted at node $x_i$), let $V_i(h)$ denote a branch \emph{envelope}—e.g., a Top-$k$ mean of $v$ among leaves within horizon $h$ steps from $x_i$ (or within a per-branch micro-beam). We write $C(h)$ for the compute required to reach horizon $h$ and define the compute-normalized improvement between horizons $h'<h$ as
\[
g_i(h,h') \;=\; \frac{V_i(h)-V_i(h')}{C(h)-C(h')}.
\]
These quantities let us reason about \emph{marginal value of compute}, not just absolute levels.

\vspace{0.5em}
\subsection{Controller overview}
\label{sec:controller}

\textbf{Exploit--explore loop.}
LToT alternates between:
\begin{enumerate}
    \item \textbf{Mainline exploitation.} Expand nodes from $M_t$ while a compute-normalized progress statistic (e.g., an EWMA of $\Delta B_t$ per unit compute) exceeds a plateau threshold. This keeps mainlines narrow (beam- or quota-capped).
    \item \textbf{Lateral exploration via LR-SC.} When exploitation plateaus, run \emph{Lateral Racing with Short-Circuit (LR-SC)} over the lateral pool: a successive-halving style race with (i) width-aware promotion thresholds, (ii) micro-probe budgets for overflow, and (iii) \emph{short-circuit} back to exploitation immediately when a lateral branch reaches the mainline bar.
\end{enumerate}
Non-promoted lateral survivors are \emph{frozen} and can be \emph{thawed} (resumed) in later exploration phases; we resume each survivor at its previous probe depth/rung.

\begin{algorithm}[t]
\caption{LToT controller (high level)}
\label{alg:ltot-controller}
\begin{algorithmic}[1]
\State \textbf{Inputs:} initial frontier $\mathcal{F}_0$, evaluator $v$, consistency $c$, plateau thresholds; LR-SC params $(\eta,b_0,\rho, \kappa,\delta)$.
\State Initialize $M_0$ with high-$v$ children; $L_0$ with low-$v$, high-$c$ children; set bar $B_0$.
\While{budget remains}
  \State \textbf{Exploit} $M_t$ while EWMA of $\Delta B_t$ per compute $\ge \tau$ (with a small patience \& hysteresis).
  \State \textbf{Explore laterals} with LR-SC over the current lateral pool (Alg.~\ref{alg:lrscr}). \label{line:lrscr}
  \If{some lateral branch reaches $v \ge B_t + \delta$ (promotion)}
     \State add promoted node(s) to $M_t$; update $B_t$; \textbf{return} to exploitation
  \Else
     \State freeze survivors for future phases; \textbf{return} to exploitation
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\vspace{-0.5em}
\subsection{LR-SC: overflow-capped racing with short-circuit}
\label{sec:lrscr}

Let $N$ be the active lateral width.
LR-SC proceeds in rungs $r=0,1,\dots$ with \emph{culling factor} $\eta>1$.
At rung $r$ we (i) keep the top quota $Q_r=\lfloor |S_r|/\eta \rfloor$ by a robust score, (ii) also retain any \emph{rapid-riser} exceeding a width-aware bar (overflow), but give overflow branches only a \emph{micro-probe}, and (iii) \emph{short-circuit} to exploitation immediately when any branch meets the promotion bar.

\paragraph{Scores and width-aware bar.}
For branch $i$ at rung $r$ we compute a compute-normalized improvement $g_i$ (using $V_i$) and a robust standardization $z_i$ (e.g., subtract rung median and divide by a MAD-like scale).
To control ``max-of-many'' effects as width grows, we admit \emph{rapid-risers} via a width-aware bar:
\[
z_i \;\ge\; \underbrace{\kappa \sqrt{2\log |S_r|}}_{\text{width penalty}} + \delta,
\]
with $\kappa\approx 1$ and a margin $\delta>0$.
We optionally standardize scores within parent-depth bands to compare fairly across heterogeneous depths.

\paragraph{Overflow cap.}
We cap the total micro-probe budget for overflow per rung to a small fraction $\rho$ of the rung budget (e.g., $\rho\in[0.1,0.2]$), ensuring per-rung cost stays near constant.

\paragraph{Derivative-based continuation (principle and instantiation).}
We view $V_i$ as a function of horizon/compute and continue branch $i$ if a discrete derivative of order $m\in\{1,\dots,M\}$ is reliably positive:
\[
\widehat{\Delta^{(m)} V_i} \;\ge\; \text{bar}(|S_r|,M) \quad\text{with}\quad \text{bar}(|S_r|,M)\propto \sqrt{2\log(|S_r|\cdot M)}.
\]
In practice we cap $M=2$ for stability and use:
\emph{(i)} first derivative (slope) $s_i = g_i(h_r,h_{r-1})$ and
\emph{(ii)} second derivative (curvature) $\kappa_i = s_i(r)-s_i(r-1)$,
estimated over the last few rungs and normalized by compute; a third-order check may be included in an appendix.
We require \emph{repeat-to-confirm}: the condition must hold on the next micro-probe before escalation.

\begin{algorithm}[t]
\caption{LR-SC (overflow-capped successive halving with short-circuit)}
\label{alg:lrscr}
\begin{algorithmic}[1]
\State \textbf{Inputs:} active lateral set $S_r$ (size $N$), culling factor $\eta>1$, base budget $b_0$, overflow cap $\rho$, thresholds $(\kappa,\delta)$, horizon schedule $(h_0,h_1,\dots)$
\State Compute robust improvement scores $\{z_i\}_{i\in S_r}$ from compute-normalized gains (optionally depth-standardized).
\State $Q_r \leftarrow \lfloor |S_r|/\eta \rfloor$;\quad $T \leftarrow$ top $Q_r$ by $z_i$;\quad $R \leftarrow \{\,i : z_i \ge \kappa \sqrt{2\log |S_r|} + \delta\,\}$.
\State Assign budget $b_{\text{full}} = b_0 \eta^r$ to $i\in T$;\quad assign micro-probe $b_{\text{micro}}$ to up to $\lfloor \rho |S_r|\rfloor$ branches in $R\setminus T$ (by $z_i$); freeze the rest.
\State Expand per budgets to horizon $h_r$ (within-branch beam is tiny); update $V_i$, $g_i$, and bar $B_t$.
\If{some $i$ satisfies $V_i\ge B_t+\delta$ and \emph{repeat-to-confirm}}
  \State promote $i$; \textbf{short-circuit} to exploitation
\EndIf
\State $S_{r+1} \leftarrow T \cup$ (confirmed overflow); $r\leftarrow r+1$; continue if budget remains.
\end{algorithmic}
\end{algorithm}

\vspace{-0.5em}
\subsection{Promotion and safety}
\label{sec:promotion}

A lateral promotes when its envelope meets the mainline bar: $V_i \ge B_t+\delta$.
When $v$ is verifier-aligned (e.g., unit tests for code, exact-match for math), this binds promotion to correctness.
For plausibility-aligned $v$, LToT can add a lightweight dual gate at promotion time:
$V_i\!\ge\!B_t{+}\delta$ \emph{and} an aggregate path-consistency (e.g., a quantile of $\{c(\cdot)\}$ along the branch) exceeding a threshold, optionally plus a one-step \emph{re-derivation} to reduce lucky spikes.
These checks cost one micro-probe and do not change the asymptotics.

\vspace{0.5em}
\subsection{Theoretical properties}
\label{sec:theory}

We summarize the main guarantees; proofs are short and rely on standard successive-halving arguments and sub-Gaussian tail bounds for rung-wise statistics.

\paragraph{Cost law (pseudolinear in lateral width).}
Let $N_0$ be the initial lateral width.
In \emph{strict} successive halving (no overflow), the per-survivor budget at rung $r$ scales like $b_0\eta^r$, and survivors are $N_0/\eta^r$, so the rung cost is $\text{Cost}_r = N_0 b_0$ (independent of $r$).
With $R=\lceil\log_\eta N_0\rceil$ rungs, the total lateral cost is
\[
\boxed{~~\text{Total} \;=\; \Theta\!\big(N_0\,b_0\,\log_\eta N_0\big).~~}
\]
In LR-SC with overflow cap $\rho\in(0,1)$ and micro-probe $b_{\text{micro}}\ll b_0$, the rung cost is at most $(1+\rho)N_0 b_0$, hence the same asymptotic order with a constant factor $(1+\rho)$.
Short-circuit promotion can only reduce cost.
Importantly, the result holds regardless of the horizon growth schedule, as long as per-survivor spend is capped by $b_0\eta^r$ (the \emph{budget-matched} policy).

\paragraph{Rung count (short in depth).}
The number of rungs required to reduce $N_0$ laterals to $O(1)$ survivors is
$R=\lceil \log_\eta N_0\rceil$, i.e., logarithmic in lateral width.
Thus LR-SC is \emph{wide and short}: constant per-rung cost and $\Theta(\log N_0)$ rungs.

\paragraph{Mainline growth (why we keep mainlines narrow).}
If at each mainline layer we admit a fixed fraction $a$ of $k$ children (effective reproduction $r_{\text{main}}=ak>1$), then expansions to depth $D$ are $\Theta(r_{\text{main}}^D)$ (exponential).
With a beam/width cap $W$, mainline cost becomes $\Theta(D\,W\,k)$ (linear in depth).
LToT therefore keeps $W$ small and invests surplus compute in laterals, where width is cheap.

\paragraph{Width-aware threshold controls family-wise errors.}
Assume rung-wise improvement statistics are sub-Gaussian with scale $\sigma$ (across branches in $S_r$).
Setting the \emph{rapid-rise} bar at $\kappa\sigma\sqrt{2\log|S_r|}+\delta$ keeps the probability that any non-improving branch exceeds the bar uniformly bounded as $|S_r|$ grows (standard max-of-sub-Gaussian tail), and a one-step \emph{repeat-to-confirm} reduces it quadratically.

\paragraph{Horizon-lifted detection of delayed payoffs.}
Suppose a branch has a delayed payoff: there exists $H^{*}$ and $m\!\in\!\{1,2\}$ such that the $m$-th discrete derivative of $V_i$ per compute is $\ge \gamma>0$ for horizons beyond $H^{*}$.
Under a geometric horizon schedule (e.g., $h_r=2^r$ within the budget cap) and the derivative-based continuation rule with width-aware thresholds and repeat-to-confirm, the branch is detected and survives to promotion within $O(\log H^{*})$ rungs (intuitively, each rung doubles the tested horizon).
Total exploration cost remains $\Theta(N_0 \log_\eta N_0)$ because the per-survivor spend never exceeds $b_0\eta^r$.

\paragraph{Independence from nominal horizon multiplier.}
If one insists on tying per-survivor cost to a nominal horizon multiplier $\gamma$ via $c_r\propto \gamma^r$, the rung cost sums to a geometric series $N_0(\gamma/\eta)^r$.
Thus for $\gamma\le\eta$ the total remains $O(N_0\log_\eta N_0)$ (or even $O(N_0)$ when $\gamma<\eta$).
In practice we adopt the budget-matched policy: cap spend by $b_0\eta^r$ and allocate within-branch depth/width flexibly up to that cap.

\vspace{0.5em}
\subsection{Design choices and defaults}
\label{sec:defaults}

\textbf{Exploitation trigger.}
EWMA of compute-normalized mainline progress with small patience and hysteresis; depth-banded statistics if $v$ drifts with depth.

\textbf{LR-SC parameters.}
$\eta\in\{3,4,5\}$; $b_0\in\{1,2\}$ expansions; micro-probe $b_{\text{micro}}=1$; overflow cap $\rho\in[0.1,0.2]$; width-aware bar with $\kappa\!\approx\!1.0$ and a small margin $\delta$ over the mainline bar.
Derivative-based continuation with slope+curvature ($M{=}2$) using a short window and robust scales; optional third-order check in ablations.

\textbf{Promotion predicate.}
Require $V_i \ge B_t + \delta$; if $v$ is not verifier-aligned, add a minimal path-consistency aggregate and a one-step re-derivation check.
Both add at most one micro-probe and preserve the asymptotics.

\textbf{Freeze--thaw.}
Cache for each survivor: rung index, envelope $V_i$, recent improvement stats, parent depth, and a lightweight duplicate signature; resume from the same rung during the next exploration phase and evict stale or dominated branches by constant-time tests (e.g., $UCB<B_t-\delta$ for several revisits).

\textbf{Summary.}
LToT turns surplus compute into breadth where it is cheapest (laterals) while keeping mainlines narrow.
Its LR-SC core provides near-linear (pseudolinear) cost in lateral width, width-aware error control, and immediate promotion when a lateral demonstrably reaches mainline utility.

\section{Experiments}
\label{section:experiments}

\section{Results and Discussion}
\label{section:results}

\section{Future Work}
\label{section:future-work}

\section{Conclusion}
\label{section:conclusion}

% Shown only in camera-ready (not in anonymous submissions)
\ificlrfinal
\section*{Acknowledgements}
\fi

% ---- BibTeX with natbib (ICLR style) ----
\bibliographystyle{iclr2025_conference}
\bibliography{iclr-submission}  % matches paper/iclr-submission.bib

\end{document}
